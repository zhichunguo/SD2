{"titles": ["Theano: A Python framework for fast computation of mathematical expressions", "Adversarially learned inference", "Separating fact from fear: Tracking flu infections on twitter", "Professor Forcing: A New Algorithm for Training Recurrent Networks", "Discriminative Regularization for Generative Models", "Variance reduction in sgd by distributed importance sampling", "Harm de Vries, David Warde-Farley, Dustin J", "Manifold mixup: Encouraging meaningful on-manifold interpolation as a regularizer", "Investigating Twitter as a source for studying behavioral responses to epidemics", "Fortified networks: Improving the robustness of deep networks by modeling the manifold of hidden representations", "Theano: A Python framework for fast computation of mathematical expressions. arXiv e-prints, abs/1605.02688, May 2016", "GibbsNet: Iterative adversarial inference for deep graphical models", "Deep Learning for Classical Japanese Literature", "Manifold Mixup: Learning Better Representations by Interpolating Hidden States", "Actual: Actor-critic under adversarial learning", "Interpolation Consistency Training for Semi-Supervised Learning", "Adversarial Mixup Resynthesizers", "Generative models: a critical review", "Learning Generative Models with Locally Disentangled Latent Factors", "How to be reproducible", "GibbsNet: Iterative Adversarial Inference for Deep Graphical Models", "State-Reification Networks: Improving Generalization by Modeling the Distribution of Hidden Representations"], "ids": ["c9e5ce18-6a6f-445d-87d4-86d32845520f", "414be72a-6184-4187-9d5e-c40df344e775", "60fa23e2-55c5-41ea-b7d3-359d83b6ae6b", "1dddde05-d0f9-4580-bb6a-7bbd9e28c31f", "d1f32057-5185-47a6-a259-54ee7fd3dbff", "917069a7-c81a-475c-a4dd-1b294802f44b", "7118eb1c-59bb-4a09-91d8-64d4ee5ac8dc"]}