{"titles": ["CirCNN: accelerating and compressing deep neural networks using block-circulant weight matrices", "GraphR: Accelerating graph processing using ReRAM", "GraphP: Reducing communication for PIM-based graph processing with efficient data partition", "Wonderland: A Novel Abstraction-Based Out-Of-Core Graph Processing System", "E-RNN: Design optimization for efficient recurrent neural networks in FPGAs", "Hypar: Towards hybrid parallelism for deep learning accelerator array", "Scalable graph traversal on sunway taihulight with ten million cores", "Graphq: Scalable pim-based graph processing", "Performance evaluation and optimization of hbm-enabled gpu for data-intensive applications", "Hop: Heterogeneity-aware decentralized training", "AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators", "Heterogeneity-Aware Asynchronous Decentralized Training", "CSE: Parallel finite state machines with convergence set enumeration", "ReGraph: A Graph Processing Framework that Alternately Shrinks and Repartitions the Graph", "SympleGraph: Distributed Graph Processing with Precise Loop-Carried Dependency Guarantee", "Prague: High-Performance Heterogeneity-Aware Asynchronous Decentralized Training", "A NOVEL ABSTRACTION-BASED OUT-OF-CORE GRAPH PROCESSING SYSTEM"], "ids": ["0f8fbc2c-18ac-495e-b034-b50fd64d9206"]}