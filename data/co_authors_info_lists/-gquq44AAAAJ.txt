{"titles": ["The convergence of sparsified gradient methods", "Sparcml: High-performance sparse communication for machine learning", "Distributed learning over unreliable networks", "Continuous integration of machine learning models with ease. ml/ci: Towards a rigorous yet practical treatment", "Ease. ml/ci and Ease. ml/meter in action: towards data management for statistical generalization", "Speeding Up Percolator", "Building Continuous Integration Services for Machine Learning", "Lossy Image Compression with Recurrent Neural Networks: from Human Perceived Visual Quality to Classification Accuracy", "Ease. ml/snoopy in Action: Towards Automatic Feasibility Analysis for Machine Learning Application Development"], "ids": []}