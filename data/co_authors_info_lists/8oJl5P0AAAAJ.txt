{"titles": ["On Using Very Large Target Vocabulary for Neural Machine Translation", "Theano: A Python framework for fast computation of mathematical expressions", "Learning to represent spatial transformations with factored higher-order boltzmann machines", "Combining modality specific deep neural networks for emotion recognition in video", "Unsupervised learning of image transformations", "Neural networks with few multiplications", "Emonets: Multimodal deep learning approaches for emotion recognition in video", "Generating images with recurrent adversarial networks", "Recurrent neural networks for emotion recognition in video", "Learning to relate images", "Learning to solve QBF", "Theano: A Python framework for fast computation of mathematical expressions", "Montreal neural machine translation systems for WMT\u201915", "Principal surfaces from unsupervised kernel regression", "Gradient-based learning of higher-order image features", "Modeling deep temporal dependencies with recurrent grammar cells\"\"", "Modeling the joint density of two images under a variety of transformations", "Gated softmax classification", "Architectural complexity measures of recurrent neural networks", "Zero-bias autoencoders and the benefits of co-adapting features", "Learning Visual Odometry with a Convolutional Network.", "On multi-view feature learning", "Shared kernel information embedding for discriminative inference", "Regularizing rnns by stabilizing activations", "The potential energy of an autoencoder", "Shared kernel information embedding for discriminative inference", "Multiple relational embedding", "The\" Something Something\" Video Database for Learning and Evaluating Visual Common Sense.", "Denoising criterion for variational auto-encoding framework", "RATM: recurrent attentive tracking model", "On autoencoder scoring", "Unsupervised learning of depth and motion", "Dropout as data augmentation", "Learning to encode motion using spatio-temporal synchrony", "Stereopsis via deep learning", "Non-linear latent factor models for revealing structure in high-dimensional data", "How far can we go without convolution: Improving fully-connected networks", "Kernel information embeddings", "Incorporating long-range consistency in cnn-based texture generation", "Improving dimensionality reduction with spectral gradient descent", "Dropout as data augmentation", "Dual optimization of conditional probability models", "RATM: Recurrent attentive tracking model", "Learning invariant features by harnessing the aperture problem", "Learning to relate images: Mapping units, complex cells and simultaneous eigenspaces", "Deep learning vector quantization", "Modeling sequential data using higher-order relational features and predictive training", "Unsupervised kernel regression for nonlinear dimensionality reduction", "Learning to combine depth and motion", "An introduction to structured discriminative learning", "Generative adversarial metric", "Deep learning: Architectures, algorithms, applications", "Embedding via clustering: using spectral information to guide dimensionality reduction", "Fine-grained video classification and captioning", "Conservativeness of untied auto-encoders", "A unified approach to learning depth and motion features", "Feature grouping from spatially constrained multiplicative interaction", "On spatio-temporal sparse coding: Analysis and an algorithm", "Real-time activity recognition via deep learning of motion features", "The more fine-grained, the better for transfer learning", "ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING", "Hierarchical Video Understanding", "System and method for video data collection", "Evaluating visual", "ARTICLE 3: RATM: RECURRENT ATTENTIVE TRACKING MODEL", "Machine learning for vision", "IFT 6085, Fall 2013", "Gradient-based learning of higher-order features", "Structured Response Models", "Propagating errors and beliefs for large-scale nonlinear structure prediction", "CRFs in the dual", "Unsupervised Kernel Regression", "Gated Softmax Classification\u2013Errata", "Learning to encode motion using spatio-temporal synchrony", "On autoencoder scoring-Errata", "On spatio-temporal feature learning"], "ids": ["10efbb34-91d5-4532-975c-6438b41a0b11", "c9e5ce18-6a6f-445d-87d4-86d32845520f", "8766e877-9399-4ef1-9e00-a184d662fc9b", "e557fbfa-c142-4aae-8c77-dac077a02b7d", "5217d97c-5256-4bb7-b501-faf36a474ca6", "110ea25c-ce6d-4104-b18c-fdadcffea247", "01d2e4ff-ce43-4b1a-8770-43a021c2cc2b", "06d60103-cb66-4ebf-869c-87d8cdb273ff", "4494883d-ba5e-425e-b09e-79b6f1b17992", "0e39d743-fc1b-4f00-b492-7f56aeb79df5", "1e91f1c6-71e1-48c0-a274-a72853f2b02c", "c9e5ce18-6a6f-445d-87d4-86d32845520f", "0c25eb5d-61f8-4592-ada8-05ba634db750", "55bb9d8d-47bd-4d81-9ad2-b4c96f43031c", "6e1fa1ce-e528-474d-8510-27b8e6b1d06a", "843eaf5d-edf3-4ce6-ace4-5681d43ede6a", "9e9f32bf-980f-43bd-9ed6-fd41c4ebc2fc", "f248bad8-ee1c-4f71-9ae2-73be223c68d7", "b90102ce-7749-4bce-9c78-0f2d89255be9", "771359f9-1fa2-446e-b3d5-366dfc51af06", "a523ae87-2985-4305-9cc3-086d2bdd1f54", "bb1c80a1-9c7d-4b20-8832-26ca1ff2dd33", "771359f9-1fa2-446e-b3d5-366dfc51af06", "095a73a1-60a3-4825-a208-ec6ac5378de9", "9f5948a0-0345-4213-b1f9-0d5487953e6b", "d62cb858-8674-4826-be66-1b9104ee5caf", "681fc9c1-aa4d-405e-ba43-2223c5afcafe", "cb07deaa-2ad7-4283-a0c0-659479550b01", "53c4f560-3303-4a41-b49f-420390fb1a01", "a2cc6ea5-5a18-4280-95a2-6067f0f221ec", "d44fb4ce-8f41-429b-924b-ee8242fb0717", "c285ca81-d8de-438d-87d0-092bc41c21ab", "2a7822f7-dcc6-4c17-a0ca-23ae10b76ac1", "3eec643c-f4ef-4bf2-84a9-ad2d2a7a2a20", "8c1db2bb-ea07-4254-aef0-819b55da7591", "53c4f560-3303-4a41-b49f-420390fb1a01", "d62cb858-8674-4826-be66-1b9104ee5caf", "9ae30036-c194-41f0-864c-3684592b6ed5", "3abcc56f-2fbb-4efb-ac98-6bc41f17e57d", "5fa083f2-dfa7-4667-9eab-d6331dbece4b", "cfc3749a-c2de-40e3-aee7-4a4ef8fef0e1", "90adb9f5-b362-4f87-87c9-d6764929818c", "d3b2f173-9671-4b52-a943-17eaca4f44b2", "348daddd-c070-46c2-992c-922ec155ebd7", "08a9f09e-e5b0-482c-a3f2-e3436e72a8fc", "4069925f-64bc-4817-a4da-d70462009d1a", "3f625923-1972-43fe-816b-e714dbb61efa", "84e77187-6a46-4a33-8fd7-5d8209097481", "a2cc6ea5-5a18-4280-95a2-6067f0f221ec"]}