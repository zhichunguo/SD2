{"titles": ["Building end-to-end dialogue systems using generative hierarchical neural network models", "A neural network approach to context-sensitive generation of conversational responses", "A hierarchical latent variable encoder-decoder model for generating dialogues", "A hierarchical recurrent encoder-decoder for generative context-aware query suggestion", "Newsqa: A machine comprehension dataset", "deltableu: A discriminative metric for generation tasks with intrinsically diverse targets", "Iterative alternating neural attention for machine reading", "Augmented cyclegan: Learning many-to-many mappings from unpaired data", "Modeling term dependencies with quantum language models for IR", "Learning algorithms for active learning", "Machine comprehension by text-to-text neural question generation", "Z-forcing: Training stochastic recurrent networks", "Learning concept embeddings for query expansion by quantum entropy minimization", "Twin Networks: Matching the future for sequence generation", "Modeling latent topic interactions using quantum interference for information retrieval", "Compact aspect embedding for diversified query expansions", "Design of an artificial decision maker for a human-based social simulation-Experience of the SimParc project", "Constraining word embeddings by prior knowledge\u2013application to medical information retrieval", "A visual tool for bayesian data analysis: the impact of smoothing on naive bayes text classifiers", "Focused hierarchical rnns for conditional sequence processing", "Multi-level abstraction convolutional model with weak supervision for information retrieval", "Looking at vector space and language models for ir using density matrices", "PRIS at TREC2012 KBA track", "Counting to explore and generalize in text-based games", "Towards Text Generation with Adversarially Learned Neural Outlines", "An Empirical Study of Example Forgetting during Deep Neural Network Learning", "Vfunc: a deep generative model for functions", "Straight to the tree: Constituency parsing with neural syntactic distance", "Learning Hierarchical Structures On-The-Fly with a Recurrent-Recursive Model for Sequences", "Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks"], "ids": ["67e8b793-8015-420e-96d4-178e1f7b64bb", "4dcb22a0-8c16-4aed-b7cb-6c17c43874b1", "60c0ced4-0269-44a3-9f4d-cec234fa1ee9", "39ede36f-a744-4f1e-909f-53f0edc11209", "b1e3b8fa-e54b-454e-aed4-442377c6d362", "9466f6de-98bf-4f8f-b06c-3d4db12c9649", "c985c908-f18a-4ac4-a40f-6040380aea03", "d854f217-fa02-4334-ad27-43c5164ca7e3", "67b9c0d4-5266-4c7f-8928-f276ce9a4586", "6ea02647-5225-442f-8b36-dea5d64fe2d5", "0a2d98b8-f53a-4295-8f7f-782854cd328d", "4a4cdf92-070a-4ab5-97c4-8eb01ebdbdb3", "9e06d764-381c-41e3-9167-a96c6aa3ae1d", "7c21cd42-0fe1-4873-8a56-50900d45a7ea", "ec49b68b-494e-43a9-a8ef-f00db63742db"]}