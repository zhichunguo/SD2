{"titles": ["Efficient inter-node MPI communication using GPUDirect RDMA for InfiniBand clusters with NVIDIA GPUs", "S-caffe: Co-designing mpi runtimes and caffe for scalable deep learning on modern gpu clusters", "MVAPICH-PRISM: A proxy-based communication framework using InfiniBand and SCIF for Intel MIC clusters", "Designing efficient small message transfer mechanism for inter-node MPI communication on InfiniBand GPU clusters", "Efficient large message broadcast using NCCL and CUDA-aware MPI for deep learning", "A case for application-oblivious energy-efficient MPI runtime", "Designing optimized mpi broadcast and allreduce for many integrated core (mic) infiniband clusters", "Designing MPI library with dynamic connected transport (DCT) of InfiniBand: early experiences", "Power-check: An energy-efficient checkpointing framework for HPC clusters", "Parallel smith-waterman comparison on multicore and manycore computing platforms with BSP++", "Hand: A hybrid approach to accelerate non-contiguous data movement using mpi datatypes on gpu clusters", "A scalable and portable approach to accelerate hybrid HPL on heterogeneous CPU-GPU clusters", "Hybrid bulk synchronous parallelism library for clustered SMP architectures", "A framework for an automatic hybrid MPI+ OpenMP code generation.", "Designing scalable out-of-core sorting with hybrid MPI+ PGAS programming models", "Mvapich2-mic: A high performance mpi library for xeon phi clusters with infiniband", "Three high performance architectures in the parallel APMC boat", "MIC-RO: enabling efficient remote offload on heterogeneous many integrated core (MIC) clusters with InfiniBand", "Scalable Graph500 design with MPI-3 RMA", "MIC-Check: A distributed check pointing framework for the Intel many integrated cores architecture", "Re-designing CNTK deep learning framework on modern GPU enabled clusters", "Designing MPI library with on-demand paging (ODP) of infiniband: challenges and benefits", "CUDA kernel based collective reduction operations on large-scale GPU clusters", "High performance MPI datatype support with user-mode memory registration: Challenges, designs, and benefits", "A high performance broadcast design with hardware multicast and GPUDirect RDMA for streaming applications on Infiniband clusters", "Scalable MiniMD design with hybrid MPI and OpenSHMEM", "Mizan-rma: Accelerating mizan graph processing framework with mpi rma", "INAM", "Initial study of multi-endpoint runtime for MPI+ OpenMP hybrid programming model on multi-core systems", "Exploiting GPUDirect RDMA in designing high performance OpenSHMEM for NVIDIA GPU clusters", "Efficient and truly passive MPI-3 RMA using InfiniBand atomics", "GPU triggered networking for intra-kernel communications", "Designing non-blocking personalized collectives with near perfect overlap for rdma-enabled clusters", "High performance OpenSHMEM for Xeon Phi clusters: Extensions, runtime designs and application co-design", "CUDA-Aware OpenSHMEM: Extensions and Designs for High Performance OpenSHMEM on GPU Clusters", "High performance alltoall and allgather designs for infiniband mic clusters", "Exploiting maximal overlap for non-contiguous data movement processing on modern gpu-enabled systems", "High performance OpenSHMEM strided communication support with infiniband umr", "Dhabaleswar (DK) Panda, Darren Kerbyson, Adolfy Hoisie, A case for application-oblivious energy-efficient MPI runtime", "Understanding the memory-utilization of MPI libraries: challenges and designs in implementing the MPI_T interface", "Designing high performance heterogeneous broadcast for streaming applications on GPU clusters", "Porting scientific libraries to PGAS in XSEDE resources: practice and experience", "Optimizing collective communication in UPC", "Accelerating ", "Parallel biological sequence comparison on heterogeneous high performance computing platforms with BSP++", "Designing high performance communication runtime for GPU managed memory: early experiences", "High-performance coarray fortran support with mvapich2-x: Initial experience and evaluation", "Comparaison de MPI, OpenMP et MPI+ OpenMP sur un n\u0153ud multiprocesseur multic\u0153urs AMD \u00e0 m\u00e9moire partag\u00e9e", "Comparaison de MPI, OpenMP et MPI+ OpenMP sur un n\u0153ud multiprocesseur multic\u0153urs AMD \u00e0 m\u00e9moire partag\u00e9e", "Efficient reliability support for hardware multicast-based broadcast in GPU-enabled streaming applications", "High-Performance and Scalable Design of MPI-3 RMA on Xeon Phi Clusters", "The harris algorithm revisited on the cell processor", "ComP-net: command processor networking for efficient intra-kernel communications on GPUs", "MPI-GDS: High Performance MPI Designs with GPUDirect-aSync for CPU-GPU Control Flow Decoupling", "CUDA M3: Designing Efficient CUDA Managed Memory-Aware MPI by Exploiting GDR and IPC", "Enabling Performance Efficient Runtime Support for Hybrid MPI+ UPC++ Programming Models", "GPU-Aware Design, Implementation, and Evaluation of Non-blocking Collective Benchmarks", "A case for non-blocking collectives in OpenSHMEM: design, implementation, and performance evaluation using MVAPICH2-X", "PU ", "Kernel-Assisted Communication Engine for MPI on Emerging Manycore Processors", "OpenSHMEM Non-blocking Data Movement Operations with MVAPICH2-X: Early Experiences", "Offloaded GPU collectives using CORE-direct and CUDA capabilities on infiniband clusters", "Impact of InfiniBand DC transport protocol on energy consumption of all-to-all collective algorithms", "Network-related performance for gpus", "Optimized and scalable sparse triangular linear systems on networks of accelerators", "Network packet templating for gpu-initiated communication", "Hot Interconnects 26", "Optimized asynchronous training of neural networks using a distributed parameter server with eager updates", "Gpu networking using an integrated command processor", "OpenSHMEM Specification 1.4", "Introduction to AsHES Workshop", "INAM2: InfiniBand Network Analysis and Monitoring with MPI", "Scalable Out-of-core OpenSHMEM Library for HPC", "Programmation des architectures hi\u00e9rarchiques et h\u00e9t\u00e9rog\u00e8nes", "Programmation des architectures hi\u00e9rarchiques et h\u00e9t\u00e9rog\u00e8nes", "HOTI 2020", "ComP-Net", "DSS 2017", "SmartCity 2017", "HPCC 2017", "WAMCA 2016 Workshop Committee", "Welcome to ESPM2'16 workshop! As the HPC field is heading to Exascale, the role of Programming Models and Middleware is getting more important. The objectives of this workshop\u00a0\u2026", "Technical Program Committee Members", "PGAS 2015 Conference Committee", "ICPADS 2013"], "ids": ["02e973b0-ab15-49be-b6eb-42e89ec03ca0", "67a86041-9dba-45a5-ade6-36b93b6d9ebe", "b7cbb3a1-3e99-438e-9d3f-e38b4c5c9567", "bff1c723-1eab-4951-8cd3-d438450aec0f", "aa0d784d-e529-469a-97d4-31721f57741c", "e8408e03-30e1-42b4-8642-4caafb15aa57", "99747d2a-c813-4e5a-800a-e4a10b2b7efd", "c9b27d7e-0060-4828-a651-e792da10306a", "954d9e2c-baed-496d-91e5-715cfd60a1c7", "c0f5cfd0-d0ce-40cc-a90e-8c7661ead081", "d4d35704-50fe-4d30-9137-6117761d3e38", "cd5ad7d5-2179-44f0-b02d-e7b8302fdfd5", "0ffaa0ff-3852-47da-a1b7-bdd12ff29f9d", "3803144e-3976-4939-81dd-a9cc32060076", "fa27d623-71a6-445d-b601-66a0c5f5aef3", "90e941b1-3338-4fc7-a6ba-082b7e5b6068", "65be14eb-8839-4569-9068-a7c9d2e63478", "fd2b3b1e-1ca6-4dc3-ab5a-1dac83538458", "e5f350e0-1ce8-4c74-9760-971ba4627cb3", "6382bbe4-4a87-4bcc-b2fd-4db8e286534f", "e3ea950a-c4a1-4ddc-b594-f71e29ca7e45", "c157df17-66f1-497f-bc5b-c0d2bf24e49d", "d2d182d9-89c8-4b27-9251-d5569536743a", "0265953b-e4db-49e8-ad54-dd42c1965a26", "b74a3717-1981-453a-8dd6-69aa8d60aef2", "38aba84e-b2db-42ad-a648-8d3501433c31", "9aa4a060-298d-4b7a-b82a-a6a99575313f", "8c63ecb1-234c-4139-9cd5-f12592d75ee5", "50686444-f55f-4d85-b6cf-53e7318cfa7a", "7c0f683c-bb02-43d0-98e2-b733e47d1b77", "0d48cd7e-03d9-42ac-8bcd-fbc1da607c6b", "f4fc5598-d725-41f9-8f47-59e3a155e5b0", "ac73a74b-b5d6-46d6-b44c-bc6a78e66f67", "33832644-c4d6-484b-9740-fb0b504651f1", "faeeef82-3c35-419e-8248-4517cddc906a", "ee9ef011-30be-41a2-b776-9720004c349c", "7546e44f-00bf-4131-96c6-c6551811262e", "aeadf311-0ab2-4a05-9513-4879c14f0fa9", "71d7d66d-5c17-4eeb-bc83-b563f67e6a18", "c6248807-ff2d-46d7-ba17-48db39a0e61a", "edc76b99-5d51-4431-b251-d7cfa79eab28", "fef3c2b4-8d7c-4030-b89a-6d69f43d0047", "a8059079-86eb-490f-bf3e-fb818a119cd6", "b7a98aaa-1133-4b15-bd50-2b113eafcae8", "8a37c8ea-125a-4aac-8725-c52c1fea009c", "110eb91d-d22e-4a08-9779-0b681a9708ff", "6a03343b-ad9f-46b4-94b6-8a4e5bd69143", "b69437b1-aa09-48ad-b9c5-39b827bc7569", "66477223-98d6-49f4-8a32-5498157b6f62", "798b9408-6ed9-4416-b9b3-430a7ab9285a"]}