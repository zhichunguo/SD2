{"titles": ["Open MPI: A high-performance, heterogeneous MPI", "Infiniband scalability in Open MPI", "MPI support for multi-core architectures: Optimized shared memory collectives", "Coordinated garbage collection for raid array of solid state disks", "Functional partitioning to optimize end-to-end performance on many-core architectures", "Big data visual analytics for exploratory earth system simulation analysis", "Understanding lustre filesystem internals", "Big data and deep data in scanning and electron microscopies: deriving functionality from multidimensional data sets", "The Earth System Grid Federation: An open infrastructure for access to distributed geospatial data", "Workload characterization of a leadership class storage cluster", "A semi-preemptive garbage collector for solid state drives", "Jaguar: The world\u2019s most powerful computer", "High performance RDMA protocols in HPC", "Active flash: Out-of-core data analytics on flash storage", "The spider center wide file system: From concept to reality", "The common communication interface (CCI)", "D-factor: a quantitative model of application slow-down in multi-resource shared systems", "A case for standard non-blocking collective operations", "Ultrascale visualization of climate data", "Preemptible I/O scheduling of garbage collection for solid state drives", "Harmonia: A globally coordinated garbage collector for arrays of solid-state drives", "Best practices and lessons learned from deploying and operating large-scale data-centric parallel file systems", "OpenSHMEM: Towards a unified RMA model", "Efficient Object Storage Journaling in a Distributed Parallel File System.", "{LADS}: Optimizing Data Transfers Using Layout-Aware Data Scheduling", "Reducing application runtime variability on Jaguar XT5", "Monitoring tools for large scale systems", "A distributed multi-gpu system for fast graph processing", "Practical application of parallel coordinates for climate model analysis", "Lessons learned in deploying the world\u2019s largest scale Lustre file system", "Investigations on infiniband: Efficient network buffer utilization at scale", "Early experiences with node-level power capping on the Cray XC40 platform", "Analysis of implementation options for MPI-2 one-sided", "Coordinating garbage collectionfor arrays of solid-state drives", " - Improving Scalability and Performance of Multi-core InfiniBand Clusters", "Enhancing I/O throughput via efficient routing and placement for large-scale parallel file systems", "Optimizing end-to-end big data transfers over terabits network infrastructure", "Open mpi: A high performance, flexible implementation of mpi point-to-point communications", "Control replication: Compiling implicit parallelism to efficient spmd with logical regions", "A next-generation parallel file system environment for the OLCF", "I/O congestion avoidance via routing and object placement", "Web-based visual analytics for extreme scale climate science", "Accelerating data acquisition, reduction, and analysis at the spallation neutron source", "Jaguar: The world\u2019s most powerful computer system\u2013an update", "Network fault tolerance in open MPI", "Methodology for the rapid development of scalable HPC data services", "Synchronous i/o scheduling of independent write caches for an array of ssds", "ParCAT: Parallel climate analysis toolkit", "Storage Systems and Input/Output to Support Extreme Scale Science", "Programmable caches with a data management language and policy engine", "Titan: 20-petaflop Cray XK7 at Oak Ridge National Laboratory", "Analysis of Application Sensitivity to System Performance Variability in a Dynamic Task Based Runtime.", "Automatic and transparent I/O optimization with storage integrated application runtime support", "Lessons learned in deploying the world s largest scale lustre file system", "Correlating log messages for system diagnostics", "Advanced Scientific Computing Research Exascale Requirements Review. An Office of Science review sponsored by Advanced Scientific Computing Research, September 27-29, 2016\u00a0\u2026", "A case study in computational caching microservices for HPC", "End-to-End data movement using MPI-IO over routed terabits infrastructures", "Layout-aware I/O Scheduling for terabits data movement", "A quantitative analysis of performance of shared service systems with multiple resource contention", "HPSS in the Extreme Scale Era: Report to DOE Office of Science on HPSS in 2018-2022", "Integrating External Resources with a Task-Based Programming Model", "Department of Energy strategic roadmap for Earth system science data integration", "HPC s Pivot to Data", "Parallelism in system tools", "Characterizing application runtime behavior from system logs and metrics", "Exploring MPI Application Performance Under Power Capping on the Cray XC40 Platform.", "Dynamic Task Scheduling to Mitigate System Performance Variability.", "Review of enabling technologies to facilitate secure compute customization", "Towards planning scientific experiments through declarative model discovery in provenance data", "Extreme scale visual analytics", "Active flash: Performance-energy tradeoffs for out-of-core processing on non-volatile memory devices", "Multi-level hybrid cache: Impact and feasibility", "High Performance Computing Facility Operational Assessment, FY 2011 Oak Ridge Leadership Computing Facility", "Real-Time System Log Monitoring/Analytics Framework", "Understanding Lustre internals", "Infiniband scalability in Open MPI", "Mochi: Composing Data Services for High-Performance Computing Environments", "Final Technical Report-A Software Defined Storage Approach to Exascale Storage Services", "Multi-tenant isolation via reconfigurable networks", "A model for optimizing file access patterns using spatio-temporal parallelism", "The Earth System Grid Federation: An Open Infrastructure for Access to Distributed Geospatial Data", "The Earth System Grid Federation: An open infrastructure for access to distributed geospatial data", "A Next-Generation Parallel File System Environment for the OLCF", "Pathological Behavior of SSDs and Application in HPC Storage", "BER Science Network Requirements", "Earth system grid center for enabling technologies: Building a global infrastructure for climate change research", "The lustre center of excellence at ornl", "Mochi: \u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u7ec4\u5408\u6570\u636e\u670d\u52a1", "Mesoscale Science at Extreme Conditions Workshop: a Momentum Initiative Workshop", "Multiobjective Evaluation and Optimization of CMT-bone on Intel Knights Landing", "Eulerian Applications Project: Performance Portability", "Isometry: A Path-Based Distributed Data Transfer System", "Trinity: Opportunities and Challenges of a Heterogeneous System.", "Kokkos User Support Infrastructure WBS STPM12 Milestone 2", "Legion: Programming Heterogeneous, Distributed Parallel Machines", "Secure Enclaves: An Isolation-centric Approach for Creating Secure High Performance Computing Environments", "Programming Models in HPC", "Early Experiences with Node-Level Power Capping on the Cray XC40 Platform [PowerPoint]", "Secure Storage Architectures", "Department of Energy's Virtual Lab Infrastructure for Integrated Earth System Science Data", "Climate Science for a Sustainable Energy Future Test Bed and Data Infrastructure Final Report", "Department of Energy's Biological and Environmental Research Strategic Data Roadmap for Earth System Science", "Data Management and Analysis in Support of DOE Climate Science", "The Ultra-scale Visualization Climate Data Analysis Tools (UV-CDAT): Data Analysis and Visualization for Geoscience Data", "Advanced Scientific Computing Research Network Requirements: ASCR Network Requirements Review Final Report", "The global aerosol-climate model echam-ham, version 2: sensitivity to improvements in process representations", "End-to-end data movement using MPI-IO over routed terabits infrastructures. In: NDM'13 Proceedings of the Third International Workshop on Network-Aware Data Management, Article\u00a0\u2026", "A model for optimizing file access patterns using spatio-temporal parallelism", "ParCAT: A Parallel Climate Analysis Toolkit", "The Earth System Grid Federation: An open infrastructure for access to distributed geospatial data", "Comparing Coordinated Garbage Collection Algorithms for Arrays of Solid-state Drives", "SESSION 1A: WIRELESS NETWORKS I", "Building a large scale climate data system in support of HPC environment", "US Department of Energy Best Practices Workshop on File Systems & Archives San Francisco, CA September 26-27, 2011 Oak Ridge Leadership Computing Facility Position Paper", "Ultra-scale Visualization Climate Data Analysis Tools (UV-CDAT)", "Real-Time System Log Monitoring/Analytics Framework", "User Application Monitoring through Assessment of Abnormal Behaviours Recorded in RAS Logs", "The Common Communication Interface (CCI)", "Oak Ridge Leadership Computing Facility Position Paper", "High Performance Computing Facility Operational Assessment, FY 2010 Oak Ridge Leadership Computing Facility", "SciDAC's Earth System Grid Center for Enabling Technologies Semi-Annual Progress Report for the Period October 1, 2009 through March 31, 2010", "A Case for Non-Blocking Collectives in the MPI Standard", "Investigations on InfiniBand: Efficient Network Buffer Utilization at Scale.", "A Case for Standard Non-blocking Collective Operations", "Open MPI Developer\u2019s Workshop", "Efficient Journaling for the Spider Storage System", "The Earth System Grid Federation", "DOE SciDAC\u2019s Earth System Grid Center for Enabling Technologies", "MSST 2019", "The International Conference for High Performance Computing, Networking, Storage and Analysis New Orleans, Louisiana, November 13-29, 2010", "Big Data Visual Analytics for Earth System Simulation Analysis", "HOTI 2014 Technical Program Committee", "ZS: An End-to-End Data Transfer Optimization for Terabit Networks", "Technical Program Committee Members", "Pavan Balaji, Argonne National Laboratory Christian Bell, Myricom Keren Bergman, Columbia University Ron Brightwell, Sandia National Laboratories", "Optimizing File Access Patterns through the Spatio-Temporal Pipeline for Parallel Visualization and Analysis", "The Ultra-scale Visualization Climate Data Analysis Tools (UV-CDAT): Progress Report: January 1 through December 31, 2012", "HOTI 2012", "Improving I/O Performance in POP (Parallel Ocean Program)"], "ids": ["098f0ce6-b882-4dd9-bfd2-0b564560bb0b", "97ea78db-289c-4ba2-b810-f5992309385a", "bc496107-9c9f-4bf6-a208-fa10a5c3c9e5", "b241b2cb-0d98-4f58-a36b-1d7b56ad5c24", "7b0d1bdd-8fc6-405d-a4b9-418afb6ba3bb", "dc82ecf9-d915-42a5-9ab4-a7e340d9465a", "6b729f18-7b0c-46c5-a11f-13cf0f5e1af9", "1784ece3-aa98-4f64-bfc6-5ee812dedf26", "2ca5567e-e5cc-4f3a-8af4-c9dcb6d01401", "ff3b6c5a-eb3a-4eb8-a22d-e4960d0b1a27", "5b9de612-79b2-495f-9649-43a7357308e3", "940679f7-e409-449a-8190-2d3083bbb022", "fd89666b-4619-42d4-9ee8-7fda4bf0b1aa", "c4d475fe-bf9e-4f0d-853f-e8e2315e9b52", "ff0b7825-18bb-4c01-bf51-be7d2831c0b8", "86532893-7448-4eae-b3be-a94cc2b231c9", "2a259c86-bb87-46a0-a7b3-4fc93003557a", "0201132a-4007-477d-842b-7d6bd30ccea7", "71aa1d14-177e-48ab-8fb4-a4e91364bee8", "320938a5-42c7-4ca7-bdff-b010e4525780", "1dbfa9cf-02a6-48f0-aa35-ec67f31c1d71", "d85f47a8-c07b-430f-bc0e-6ec9909f4796", "2052637b-d6e4-4e69-83c2-d3c057ca5d3b", "c1528e6b-b1b2-478d-bf51-f5f55836497b", "70a461f1-2baa-45e2-a05c-c8993e09d455", "effd1035-c437-4ced-add4-6b940f1b7e4b", "4400165a-12aa-42ff-ab93-9d6f93ef49a4", "10538200-8e1d-488b-ad99-ff5430c61450", "0ad7359e-2df4-4b9c-bfd1-32bd072dbc57", "c41c95a8-7dfe-4c6c-9dc9-09dbf840eedf", "72b4558d-c83c-4bfb-91f9-281371be0f90", "66426c52-849e-4de3-8c0d-8dc072a186a3", "55fa71cd-2591-48b2-9e82-8d2acb6c15db", "4ddfdf37-003e-4e2f-93ad-7eb4d564643b", "df3d828f-78e3-40cf-b320-617b160d15a3", "0acde60b-bd4b-4791-80c1-69b9ae3bf92c", "cd7197e2-8d2c-4a41-9e5b-b61abe752491", "c44073e3-fea6-4cad-856f-3727b0a89d12", "02bc3b9b-8345-4aab-87c2-f3e173b1bbcc", "c1682dd9-8c56-411a-836b-658e311b9a18", "3d8db66c-52b8-4c9c-b412-d876cb6e1829", "ceadce61-db0e-48f7-91da-0294c3c487af", "21cc994f-1dc3-4eb0-8217-e4022876aeec", "33fb4ee7-2988-49da-9983-b5114ca354b6", "6f4965f7-4c23-4cd9-9461-2cbaa56b622d", "e61c68e9-e653-406e-9da4-2277c6bc949c", "6bcf485b-cef0-4439-a996-a700a55d6745", "d1f894cf-569b-4c62-a4eb-7854bec45e4b", "d6d784e5-722b-475e-bf9e-f2b53c953ee2", "6859a36d-c1c1-4459-b72a-9570aff57395", "7cbd904d-a0d6-4ae3-863e-66d9d433e682", "b8b2043e-2c2c-4da1-a5eb-2d75f9a6fe5d", "19bca818-7270-45c9-88ba-b2103270e074", "7852a6fe-f28a-4eaa-9d1d-93cf43c5fd4c", "5cd4b270-71de-44f8-a21d-fecfabf1a673", "633e0bd6-3b58-4e97-b44e-d8802e318560", "97ea78db-289c-4ba2-b810-f5992309385a", "5a525fbf-2364-48c3-8cf4-659afce94217", "eadb0419-dba9-4ad3-9a13-5fc48eb36f47", "2ca5567e-e5cc-4f3a-8af4-c9dcb6d01401", "2ca5567e-e5cc-4f3a-8af4-c9dcb6d01401", "72b4558d-c83c-4bfb-91f9-281371be0f90", "5897172c-b1fb-4f82-bae0-617f1dfb881a", "9946ca62-74e9-4f34-b63f-e5bccb17f7ba", "45ae4662-3a0a-4b76-a999-c48adfe33236", "0a364945-41b3-47c0-b19b-2eea2329966c", "107843f9-ace2-4706-a6ea-e5218f50627f", "2f7355ec-add0-4b96-90ff-804cc2b31637", "a9fc1ade-1c6b-4015-b35d-4e14692643f1", "4516e4eb-8b57-4cb7-a913-69bef895e59e", "eadb0419-dba9-4ad3-9a13-5fc48eb36f47", "2ca5567e-e5cc-4f3a-8af4-c9dcb6d01401", "8e8fae55-7bf5-4e22-b1b5-fd5eeaffe43a", "4e338156-c30c-42b6-be16-fffaccfef9d5", "1240f78c-de8f-4f81-bee0-55ed5cac2e68", "5cd4b270-71de-44f8-a21d-fecfabf1a673", "5c2b27a0-4d6c-441e-bd89-48824a87a3a4", "c4d475fe-bf9e-4f0d-853f-e8e2315e9b52", "32b17eed-473d-468c-9d12-76168fda304d", "86532893-7448-4eae-b3be-a94cc2b231c9", "9d839ed3-b4b0-4abc-a3c9-9dac1bbe0486", "66477223-98d6-49f4-8a32-5498157b6f62"]}