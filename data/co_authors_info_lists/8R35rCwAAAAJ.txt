{"titles": ["Trust region policy optimization", "End-to-end training of deep visuomotor policies", "Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection", "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks", "High-dimensional continuous control using generalized advantage estimation", "Unsupervised learning for physical interaction through video prediction", "Guided Policy Search", "Continuous deep q-learning with model-based acceleration", "Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates", "Learning neural network policies with guided policy search under unknown dynamics", "Guided cost learning: Deep inverse optimal control via policy optimization", "Value iteration networks", "Deep Spatial Autoencoders for Visuomotor Learning", "Recurrent network models for human dynamics", "Learning to poke by poking: Experiential learning of intuitive physics", "Nonlinear inverse reinforcement learning with gaussian processes", "Continuous inverse optimal control with locally optimal examples", "Learning contact-rich manipulation skills with guided policy search", "CAD2RL: Real Single-Image Flight without a Single Real Image", "Deep visual foresight for planning robot motion", "Cognitive mapping and planning for visual navigation", "Reinforcement learning with deep energy-based policies", "Learning deep control policies for autonomous aerial vehicles with mpc-guided policy search", "Incentivizing exploration in reinforcement learning with deep predictive models", "Q-prop: Sample-efficient policy gradient with an off-policy critic", "Continuous character control with low-dimensional embeddings", "Real-time prosody-driven synthesis of body language", "Using simulation and domain adaptation to improve efficiency of deep robotic grasping", "Learning visual predictive models of physics for playing billiards", "Learning hand-eye coordination for robotic grasping with large-scale data collection", "Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning", "Towards adapting deep visuomotor representations from simulated to real environments", "Gesture controllers", "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor", "Learning modular neural network policies for multi-task and multi-robot transfer", "One-shot visual imitation learning via meta-learning", "Learning Complex Neural Network Policies with Trajectory Optimization", "Time-contrastive networks: Self-supervised learning from video", "Variational policy search via trajectory optimization", "Modular multitask reinforcement learning with policy sketches", "A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models", "Epopt: Learning robust neural network policies using model ensembles", "Muprop: Unbiased backpropagation for stochastic neural networks", "Stochastic variational video prediction", "Feature construction for inverse reinforcement learning", "Deepmimic: Example-guided deep reinforcement learning of physics-based character skills", "Learning invariant feature spaces to transfer skills with reinforcement learning", "One-shot learning of manipulation skills with online dynamics adaptation and neural network priors", "Plato: Policy learning using adaptive trajectory optimization", "Learning Force-Based Manipulation of Deformable Objects from Multiple Demonstrations", "Offline policy evaluation across representations with applications to educational games", "Uncertainty-aware reinforcement learning for collision avoidance", "Space-time planning with parameterized locomotion controllers", "Recasting gradient-based meta-learning as hierarchical bayes", "Learning complex dexterous manipulation with deep reinforcement learning and demonstrations", "Guided policy search via approximate mirror descent", "Path integral guided policy search", "Learning dexterous manipulation for a soft robotic hand from human demonstrations", "Imitation from observation: Learning to imitate behaviors from raw video via context translation", "One-shot imitation from observing humans via domain-adaptive meta-learning", "Learning robust rewards with adversarial inverse reinforcement learning", "Optimal control with learned local models: Application to dexterous manipulation", "Collective robot reinforcement learning with distributed asynchronous guided policy search", "Self-supervised visual planning with temporal skip connections", "Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning", "Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning", "Unsupervised perceptual rewards for imitation learning", "Diversity is all you need: Learning skills without a reward function", "Learning deep neural network policies with continuous memory states", "Stochastic adversarial video prediction", "Temporal difference models: Model-free deep rl for model-based control", "Self-supervised deep reinforcement learning with generalized computation graphs for robot navigation", "Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation", "Combining self-supervised learning and imitation for vision-based rope manipulation", "Learning Visual Servoing with Deep Features and Fitted Q-Iteration", "Meta-learning and universality: Deep representations and gradient descent can approximate any learning algorithm", "The feeling of success: Does touch sensing help predict grasp outcomes?", "Reinforcement learning and control as probabilistic inference: Tutorial and review", "Universal planning networks", "Ex2: Exploration with exemplar models for deep reinforcement learning", "Probabilistic model-agnostic meta-learning", "Exploring Deep and Recurrent Architectures for Optimal Control", "Vision-based multi-task manipulation for inexpensive robots using end-to-end learning from demonstration", "Deep reinforcement learning in a handful of trials using probabilistic dynamics models", "Data-efficient hierarchical reinforcement learning", "Deep reinforcement learning for tensegrity robot locomotion", "Generalizing skills with semi-supervised reinforcement learning", "Goal-driven dynamics learning via bayesian optimization", "Optimism-Driven Exploration for Nonlinear Systems", "Physically plausible simulation for character animation", "Composable deep reinforcement learning for robotic manipulation", "Reset-free guided policy search: Efficient deep reinforcement learning with stochastic initial states", "Model-based reinforcement learning with parametrized physical models and optimism-driven exploration", "Unifying map and landmark based representations for visual navigation", "Inverse Optimal Control for Humanoid Locomotion", "Learning to adapt: Meta-learning for model-based control", "Reinforcement learning from imperfect demonstrations", "Learning from multiple demonstrations using trajectory-aware non-rigid registration with applications to deformable object manipulation", "The mirage of action-dependent baselines in reinforcement learning", "More than a feeling: Learning to grasp and regrasp using vision and touch", "Meta-reinforcement learning of structured exploration strategies", "Deep reinforcement learning for vision-based robotic grasping: A simulated comparative evaluation of off-policy methods", "Latent space policies for hierarchical reinforcement learning", "Learning from the hindsight plan\u2014episodic mpc improvement", "Learning compound multi-step controllers under unknown dynamics", "End-to-end learning of semantic grasping", "Self-consistent trajectory autoencoder: Hierarchical reinforcement learning with trajectory embeddings", "Visual reinforcement learning with imagined goals", "Sim2Real Viewpoint Invariant Visual Servoing by Recurrent Control", "Neural network dynamics models for control of under-actuated legged millirobots", "Recurrent network models for kinematic tracking", "Divide-and-conquer reinforcement learning", "Model-based value estimation for efficient model-free reinforcement learning", "Learning dexterous manipulation policies from experience and imitation", "Deep object-centric representations for generalizable robot learning", "Recall traces: Backtracking models for efficient reinforcement learning", "Mbmf: Model-based priors for model-free reinforcement learning", "Gplac: Generalizing vision-based robotic skills using weakly labeled images", "Sfv: Reinforcement learning of physical skills from videos", "Shared autonomy via deep reinforcement learning", "Leave no trace: Learning to reset for safe and autonomous reinforcement learning", "Learning with latent language", "Conditional networks for few-shot semantic segmentation", "Learning to Run challenge solutions: Adapting reinforcement learning methods for neuromusculoskeletal environments", "Learning to run challenge: Synthesizing physiologically accurate motion using deep reinforcement learning", "Regret minimization for partially observable deep reinforcement learning", "Policy learning with continuous memory states for partially observed robotic control", "System and method for robust physically-plausible character animation", "Motor skill learning with local trajectory methods", "Soft Actor-Critic Algorithms and Applications", "Unsupervised learning via meta-learning", "Few-shot goal inference for visuomotor learning and planning", "Visual Foresight: Model-Based Deep Reinforcement Learning for Vision-Based Robotic Control", "Grasp2vec: Learning object representations from self-supervised grasping", "Solar: Deep structured latent representations for model-based reinforcement learning", "Unsupervised Meta-Learning for Reinforcement Learning", "Body language animation synthesis from prosody", "Sim-to-Real via Sim-to-Sim: Data-efficient Robotic Grasping via Randomized-to-Canonical Adaptation Networks", "Residual reinforcement learning for robot control", "Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost", "Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning", "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "Automatically composing representation transformations as a means for generalization", "Universal planning networks: Learning generalizable representations for visuomotor control", "Learning flexible and reusable locomotion primitives for a microrobot", "Learning a prior over intent via meta-inverse reinforcement learning", "Few-Shot Segmentation Propagation with Guided Networks", "Variational inverse control with events: A general framework for data-driven reward definition", "Learning robotic manipulation of granular media", "Deep Online Learning via Meta-Learning: Continual Adaptation for Model-Based RL", "Near-Optimal Representation Learning for Hierarchical Reinforcement Learning", "Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning", "Time-Agnostic Prediction: Predicting Predictable Video Frames", "Learning instance segmentation by interaction", "Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior", "Accelerating Human Learning with Deep Reinforcement Learning", "End-toend training of deep visuomotor policies. arXiv preprint arXiv: 1504.00702", "Learning Dynamic Manipulation Skills under Unknown Dynamics with Guided Policy Search", "Online Meta-Learning", "From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following", "Generalization through Simulation: Integrating Simulated and Real Data into Deep Reinforcement Learning for Vision-Based Autonomous Flight", "Robustness to out-of-distribution inputs via task-aware generative uncertainty", "Learning Actionable Representations with Goal-Conditioned Policies", "One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks", "Few-Shot Intent Inference via Meta-Inverse Reinforcement Learning", "Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning", "Learning to Adapt: Meta-Learning for Model-Based Control", "Visual Memory for Robust Path Following", "Concept acquisition through meta-learning", "Cognitive Mapping and Planning for Visual Navigation Supplementary Material", "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables", "Manipulation by Feel: Touch-Based Control with Deep Predictive Models", "Learning to Identify Object Instances by Touch: Tactile Recognition via Multimodal Matching", "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning", "Learning Latent Plans from Play", "VideoFlow: A Flow-Based Generative Model for Video", "Model-Based Reinforcement Learning for Atari", "Diagnosing Bottlenecks in Deep Q-learning Algorithms", "Artificial Intelligence for Prosthetics-challenge solutions", "InfoBot: Transfer and Exploration via the Information Bottleneck", "Low Level Control of a Quadrotor with Deep Model-Based Reinforcement learning", "Reasoning About Physical Interactions with Object-Oriented Prediction and Planning", "Learning to Walk via Deep Reinforcement Learning", "Hierarchical policy design for sample-efficient learning of robot table tennis through self-play", "Guiding Policies with Language via Meta-Learning", "Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation", "Deep Imitative Models for Flexible Inference, Planning, and Control", "EMI: Exploration with Mutual Information Maximizing State and Action Embeddings", "Time Reversal as Self-Supervision", "What would pi* do?: Imitation learning via off-policy reinforcement learning", "Unsupervised Exploration with Deep Model-Based Reinforcement Learning", "Learning to Reinforcement Learn by Imitation", "Hierarchical Deep Reinforcement Learning Agent with Counter Self-play on Competitive Games", "Deep machine learning methods and apparatus for robotic grasping", "Deep machine learning methods and apparatus for robotic grasping", "Grasp2Vec: Learning Object Representations from Self-Supervised Grasping", "Introduction to NIPS 2017 Competition Track", "Deep machine learning methods and apparatus for robotic grasping", "Deep machine learning methods and apparatus for robotic grasping", "Reinforcement learning using advantage estimates", "Learning to Manipulate Granular Media with a Robot", "End to end active perception", "Learning 2D Linear Dynamics in Image Space Using Neural Networks", "Learning Locomotion Controllers via Trajectory Optimization", "Learning Locomotion Controllers with a Policy Iteration Algorithm", "System and Method for Robust Physically-Plausible Character Animation", "Modeling body language from speech in natural conversation", "Method and system for delivering prescription medicine", "Learning Force-Based Manipulation of Deformable Objects from Multiple Demonstrations", "Causal Confusion in Imitation Learning", "Interpolated Policy Gradient", "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement", "Learning Long-term Dependencies with Deep Memory States", "Language Learning as Meta-Learning", "Combining Model-Based and Model-Free Updates for Deep Reinforcement Learning", "Ensemble Policy Optimization for Learning Robust Policies"], "ids": ["556e1d01-bff1-45cd-8f30-b419545f4858", "c64a5fb6-004c-4101-9d4c-84c46d03cfdd", "218049fa-4dc2-468a-bce8-d70f996fa445", "97647296-caf4-459f-9ec5-501846ec6449", "d8d9ff15-b8c7-4f68-a658-27af96f1737e", "6c6efc96-8314-434e-8dff-ffd06f8267a3", "1e843889-3a58-409c-a9c1-befcfa5828e8", "738f54ef-4d53-4ebb-90ee-8907ce6a8404", "fabfd5d4-970c-4bf0-aaac-d07e9c31e013", "5523fd1d-a97f-422a-b520-8743720f9941", "662b49c6-7aa8-4a91-9bd7-35ac93852bee", "4d97eb79-1b65-48e0-8aba-bdeec8e59009", "8c7a58a4-c58c-4485-8e8d-af3f01e14bc9", "d0d5dfd3-b3c8-4446-b801-fd192d853266", "dbde1839-4b10-4799-a632-a00df0671719", "49b3f88c-2196-48b1-928c-c5e349ae1524", "c2b82656-f308-43bd-92cb-853062f14b89", "6883dcb3-012d-49d5-bd9e-ad22ba1bf7e6", "eb95b4cd-12cf-424e-91fe-bf240236a033", "64d0156a-e1b7-49e6-a1a1-9fbbe88abb74", "a18a3bdc-7f79-47b6-88de-9459bd48e135", "71230114-70d1-4d49-a310-cf5866383209", "4f16ff73-9e5b-4091-8732-925e060f1609", "d9ea8b1a-6c49-4daa-8535-cf6eeedd850f", "4ed5406a-0b46-4103-bce0-7ceab8b401bb", "8aac7d40-8021-40a4-9fe1-4d422963bb32", "e2d49d8f-027b-44e9-99bf-5a100d290170", "37a7614c-b181-4b89-950e-5142030edfdf", "3ac37516-3f59-453e-b4a8-f87dbbf23162", "e4e9e561-c96a-476e-9d7b-0fb49220fffc", "7b8b5273-33f2-497e-aa41-b32a06e1453a", "abaee661-7b00-4fcd-a2d3-4788e591e374", "08feb3e2-24ff-4ce7-b091-11d2567d9f9e", "8d7375d3-b901-438d-9c41-54d812c1b73f", "33e55c77-e6b0-416a-9fb1-d92abdcc95c0", "37d8d7d1-5e5f-451a-8dd5-38da98f70861", "52d52508-bcbb-4fad-b8da-212102ff83e5", "dda5d6e8-48e0-4a5d-b1aa-6f09fdf51c2a", "d2652eec-0494-4b49-a38c-98853418a0c8", "1169db66-b4c0-41fc-92c6-51bd698e23fc", "26f19190-c77d-4f75-bdbe-a5eda4d809d9", "71e2242e-221f-48d5-9730-2a5f9450ef78", "65742965-084b-4d46-aee4-3d982a291689", "a5c0fd7e-ba08-42b8-b758-ac2fec9d8c9c", "aed8f614-de57-45d8-a14b-5fbfe66f54ab", "e776cf1f-4340-4737-802e-0f9754c76488", "ff6af246-d2ee-439f-a285-788b3ca28790", "aaae14fb-853c-402b-a0a5-6462ca0f9202", "321b4ad1-7f29-44de-8cb1-a4b8f2173464", "228d4e5d-8a1e-4330-9036-d58fbb6ca35c", "c014ab5d-8b25-4c54-9140-4e08f5878328", "c0611d45-e65f-45f0-be6d-0747756e35e3", "e2bd9a9f-997f-4c94-8584-be0a12a27eb4", "342ed73b-c861-4431-9650-2915a382023f", "eb0fbb0d-6add-4053-9c49-5031e5bd9a5d", "20916704-450d-43d9-a148-3411106f3d30", "0361e3cf-bd5e-4234-904d-23c388c1ec79", "9ed87d1e-7eb3-448b-88b8-a74dadc347d0", "054f4531-a48d-46d7-a84e-df01684b80e6", "2568d7d0-7d99-4e1a-b5c1-75b17ce87212", "624bb228-e16e-4fc4-8535-e19e42403d98", "37ed07fb-97ba-43c7-b2ca-b9ee96991e8c", "80891a50-1e8e-4c59-843a-9ad06f10e12b", "fce0f359-2026-446f-84d8-407bfd6d82f8", "9e83771a-05fd-4af8-842b-0b30e71e151a", "4d1e2385-fef4-4056-89fb-361e3dd80da5", "8b38d23d-5309-4501-a469-8146aebb0196", "fa915075-5d55-4bbb-8a1f-236bb8112dc9", "fa915075-5d55-4bbb-8a1f-236bb8112dc9", "7df14802-dcbb-4d27-bc84-33fc4f94bb40", "71e2242e-221f-48d5-9730-2a5f9450ef78"]}